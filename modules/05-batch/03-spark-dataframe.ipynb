{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "\n",
    "WDIR = os.path.abspath(os.path.dirname(\"\"))\n",
    "print(f\"pyspark.__version__: {pyspark.__version__}\")\n",
    "print(WDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/02 23:23:19 WARN Utils: Your hostname, Ronalds-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.1.227 instead (on interface en0)\n",
      "24/03/02 23:23:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/02 23:23:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/02 23:23:32 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('bucket/fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0005|              B02510|2021-01-10 17:40:01|2021-01-10 17:48:10|          97|          25|   NULL|\n",
      "|           HV0005|              B02510|2021-01-08 18:19:44|2021-01-08 18:55:57|         138|         265|   NULL|\n",
      "|           HV0003|              B02876|2021-01-01 16:47:20|2021-01-01 16:58:28|          50|         163|   NULL|\n",
      "|           HV0005|              B02510|2021-01-15 17:50:08|2021-01-15 18:07:24|         163|          79|   NULL|\n",
      "|           HV0005|              B02510|2021-01-12 17:26:40|2021-01-12 17:57:57|          47|          74|   NULL|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actions vs Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[hvfhs_license_num: string, pickup_datetime: timestamp, dropoff_datetime: timestamp, PULocationID: int, DOLocationID: int]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not execute -> Transformation\n",
    "df.select('hvfhs_license_num', 'pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-------------------+------------+------------+\n",
      "|hvfhs_license_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-----------------+-------------------+-------------------+------------+------------+\n",
      "|           HV0003|2021-01-01 16:47:20|2021-01-01 16:58:28|          50|         163|\n",
      "|           HV0003|2021-01-05 02:00:14|2021-01-05 02:19:39|          48|          95|\n",
      "|           HV0003|2021-01-02 00:34:43|2021-01-02 00:45:38|          63|          77|\n",
      "|           HV0003|2021-01-02 16:20:11|2021-01-02 16:56:36|          63|         244|\n",
      "|           HV0003|2021-01-24 16:00:53|2021-01-24 16:07:40|         210|         165|\n",
      "+-----------------+-------------------+-------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With show -> executed\n",
    "df.select('hvfhs_license_num', 'pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+------------+------------+------------+\n",
      "|hvfhs_license_num|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------------+-----------+------------+------------+------------+\n",
      "|           HV0003| 2021-01-01|  2021-01-01|          50|         163|\n",
      "|           HV0003| 2021-01-05|  2021-01-05|          48|          95|\n",
      "|           HV0003| 2021-01-02|  2021-01-02|          63|          77|\n",
      "|           HV0003| 2021-01-02|  2021-01-02|          63|         244|\n",
      "|           HV0003| 2021-01-24|  2021-01-24|         210|         165|\n",
      "+-----------------+-----------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .select('hvfhs_license_num', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udf - things that are hard to implement in SQL\n",
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[2:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s/b44'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python-testable udf\n",
    "crazy_stuff('BV02884')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register udf function\n",
    "from pyspark.sql import types\n",
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+-----------+------------+------------+------------+\n",
      "|hvfhs_license_num|base_id|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------------+-------+-----------+------------+------------+------------+\n",
      "|           HV0003|  e/003| 2021-01-01|  2021-01-01|          50|         163|\n",
      "|           HV0003|  e/003| 2021-01-05|  2021-01-05|          48|          95|\n",
      "|           HV0003|  e/003| 2021-01-02|  2021-01-02|          63|          77|\n",
      "|           HV0003|  e/003| 2021-01-02|  2021-01-02|          63|         244|\n",
      "|           HV0003|  e/003| 2021-01-24|  2021-01-24|         210|         165|\n",
      "+-----------------+-------+-----------+------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .withColumn('base_id', crazy_stuff_udf(df.hvfhs_license_num)) \\\n",
    "    .select('hvfhs_license_num', 'base_id', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
